{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5UTMFBeOWNKp","executionInfo":{"status":"ok","timestamp":1763893079554,"user_tz":-420,"elapsed":3928,"user":{"displayName":"Abhimanyu","userId":"02570476676756296416"}},"outputId":"c749ceed-86e7-4059-8c05-9651f7e587a5"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","from getpass import getpass\n","\n","# üîπ Your ML project folder (EXACT PATH)\n","project_path = \"/content/drive/MyDrive/Project\" # your path\n","os.chdir(project_path)\n","\n","print(\"Working directory:\", os.getcwd())\n","!ls\n","\n","# # üîπ Initialize Git (safe to run even if repo already exists)\n","# !git init\n","\n","# üîπ Git user identity\n","!git config --global user.name \"manyu-88\"\n","!git config --global user.email \"abhimanyu_shirwalkar2015@pgp.isb.edu\"\n","\n","# üîπ Ensure main branch\n","!git branch -M main\n","\n","# üîπ GitHub repo config (EXACT FOR YOU)\n","username = \"manyu-88\"\n","repo_name = \"stock-price-model\" # your repo\n","\n","# # üîπ Ask for GitHub Personal Access Token secretly\n","token = getpass(\"Enter your GitHub Personal Access Token: \")\n","\n","# üîπ Set remote origin (replace if exists)\n","remote_url = f\"https://{token}@github.com/{username}/{repo_name}.git\"\n","!git remote remove origin 2>/dev/null || true\n","!git remote add origin $remote_url\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rnU3-1j9TNG_","executionInfo":{"status":"ok","timestamp":1763893257505,"user_tz":-420,"elapsed":6350,"user":{"displayName":"Abhimanyu","userId":"02570476676756296416"}},"outputId":"76e38983-a481-423e-ab2f-fdd55e324f26"},"execution_count":24,"outputs":[{"name":"stdout","output_type":"stream","text":["Working directory: /content/drive/MyDrive/Project\n"," output.xlsx  'Stock Price Prediction.gslides'\t'Stock Price_Random Forest_v1'\n","Enter your GitHub Personal Access Token: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"]}]},{"cell_type":"code","source":["# üîπ Add and commit everything\n","!git add .\n","!git commit -m \"Second Run for Stock Price Prediction ML project w Basic RF\"\n","\n","# üîπ Push to GitHub\n","!git push -u origin main\n","!git push -u origin main --force"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oCK9IyovXyGw","executionInfo":{"status":"ok","timestamp":1763893311356,"user_tz":-420,"elapsed":1932,"user":{"displayName":"Abhimanyu","userId":"02570476676756296416"}},"outputId":"ea18f878-43d0-4297-8a34-7bdd01f51a9f"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["error: open(\"Stock Price Prediction.gslides\"): Operation not supported\n","error: unable to index file 'Stock Price Prediction.gslides'\n","fatal: adding files failed\n","On branch main\n","Changes not staged for commit:\n","  (use \"git add/rm <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\t\u001b[31mdeleted:    Stock Price_v2\u001b[m\n","\t\u001b[31mmodified:   output.xlsx\u001b[m\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\t\u001b[31mStock Price_Random Forest_v1\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n","Branch 'main' set up to track remote branch 'main' from 'origin'.\n","Everything up-to-date\n","Branch 'main' set up to track remote branch 'main' from 'origin'.\n","Everything up-to-date\n"]}]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":12077,"status":"ok","timestamp":1763893095919,"user":{"displayName":"Abhimanyu","userId":"02570476676756296416"},"user_tz":-420},"id":"jOKOBZlwN1a5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4226198d-336c-4ef9-f061-21b1afa288fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: schedule in /usr/local/lib/python3.12/dist-packages (1.2.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n"]}],"source":["!pip install schedule\n","!pip install requests"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"EIKTsRpDOIVB","executionInfo":{"status":"ok","timestamp":1763893095922,"user_tz":-420,"elapsed":1,"user":{"displayName":"Abhimanyu","userId":"02570476676756296416"}}},"outputs":[],"source":["import time\n","import requests\n","import pandas as pd\n","from datetime import datetime,timedelta\n","import schedule\n","import pytz\n","import csv\n","import yfinance as yf"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"ex1Vd4LPOQU2","executionInfo":{"status":"ok","timestamp":1763893095955,"user_tz":-420,"elapsed":18,"user":{"displayName":"Abhimanyu","userId":"02570476676756296416"}}},"outputs":[],"source":["import time\n","import requests\n","import pandas as pd\n","from datetime import datetime, timedelta\n","import schedule\n","import pytz\n","import csv\n","import yfinance as yf\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import RandomForestRegressor\n","\n","# üõ†Ô∏è FIX: Import for the downstream error 'train_test_split is not defined'\n","from sklearn.model_selection import train_test_split\n","\n","class TickerInfo:\n","    \"\"\"Class to hold the prediction results for each stock.\"\"\"\n","    def __init__(self, name, score, delta):\n","        self.name = name\n","        self.score = score\n","        self.delta = delta\n","\n","class StockAPI():\n","    \"\"\"Handles data retrieval from yfinance.\"\"\"\n","\n","    def __init__(self):\n","        # Set a realistic historical date range (e.g., 2 years ending in mid-2025)\n","        self.date_end = datetime(2025, 11, 15)\n","        # Calculate start date ~2 years back, adjusting for trading days\n","        self.date_start = self.date_end - timedelta(days=2 * 365 + 10)\n","\n","        # Fetch bond data once upon initialization\n","        self.closing_yield = self._fetch_yield_data()\n","        print(\"Bond Yield data fetched successfully and stored.\")\n","\n","    def _fetch_yield_data(self):\n","        \"\"\"\n","        Fetches 5Y and 10Y T-Bond yield data once using yfinance.\n","        Guarantees return of an indexed DataFrame (or an empty one).\n","        \"\"\"\n","        end_date_str = self.date_end.strftime(\"%Y-%m-%d\")\n","        start_date_str = self.date_start.strftime(\"%Y-%m-%d\")\n","\n","        # Default empty DataFrame to return on failure\n","        empty_df = pd.DataFrame({'from': pd.Series([], dtype='datetime64[ns]'),\n","                                 '5Y_close': [],\n","                                 '10Y_close': []})\n","        try:\n","            # Setting progress=False to suppress output during download\n","            # Added auto_adjust=False to suppress FutureWarning\n","            tbond_5y = yf.download(tickers=\"^FVX\", start=start_date_str, end=end_date_str, progress=False, auto_adjust=False)\n","            tbond_10y = yf.download(tickers=\"^TNX\", start=start_date_str, end=end_date_str, progress=False, auto_adjust=False)\n","\n","            # Robustly handle potential MultiIndex in bond data (Fix 2)\n","            if isinstance(tbond_5y.columns, pd.MultiIndex):\n","                tbond_5y.columns = tbond_5y.columns.get_level_values(0)\n","            if isinstance(tbond_10y.columns, pd.MultiIndex):\n","                tbond_10y.columns = tbond_10y.columns.get_level_values(0)\n","\n","            # Reset index to move 'Date' from index to a column for merging\n","            tbond_5y = tbond_5y.reset_index()\n","            tbond_10y = tbond_10y.reset_index()\n","\n","        except Exception as e:\n","            print(f\"Error during yfinance download for bonds: {e}\")\n","            return empty_df\n","\n","        # Robust check for valid time-series data\n","        has_5y_data = 'Close' in tbond_5y.columns and len(tbond_5y) > 1\n","        has_10y_data = 'Close' in tbond_10y.columns and len(tbond_10y) > 1\n","\n","        if not has_5y_data or not has_10y_data:\n","            print(\"WARNING: Bond data is incomplete or empty. Returning empty DataFrame.\")\n","            return empty_df\n","\n","        try:\n","            # Select the Date and Close columns and rename the Close columns\n","            df_5y = tbond_5y[['Date', 'Close']].rename(columns={'Close': '5Y_close'})\n","            df_10y = tbond_10y[['Date', 'Close']].rename(columns={'Close': '10Y_close'})\n","\n","            # Use pd.merge to combine the two dataframes on the common 'Date' column\n","            closing_yield = pd.merge(df_5y, df_10y, on='Date', how='inner')\n","\n","            # Rename the 'Date' column to 'from' to match the stock data format\n","            closing_yield = closing_yield.rename(columns={'Date': 'from'})\n","\n","            # üõ†Ô∏è FIX: Update fillna syntax to suppress FutureWarning\n","            closing_yield['5Y_close'] = closing_yield['5Y_close'].ffill()\n","            closing_yield['10Y_close'] = closing_yield['10Y_close'].ffill()\n","\n","            return closing_yield\n","\n","        except Exception as e:\n","            # Catch errors during processing\n","            print(f\"Error processing bond data after download: {e}\")\n","            return empty_df\n","\n","    def update_stock_data(self, ticker):\n","\n","        start_date_str = self.date_start.strftime(\"%Y-%m-%d\")\n","        end_date_str = self.date_end.strftime(\"%Y-%m-%d\")\n","\n","        # 1. Fetch historical OHLCV data for the entire range using yfinance\n","        try:\n","            df = yf.download(ticker, start=start_date_str, end=end_date_str, progress=False, auto_adjust=False)\n","\n","            if isinstance(df.columns, pd.MultiIndex):\n","                # Dropping the second level (the ticker symbol) from the MultiIndex\n","                df.columns = df.columns.droplevel(1)\n","\n","            # Move Date index to 'from' column\n","            df = df.reset_index().rename(columns={'Date': 'from'})\n","\n","        except Exception as e:\n","            print(f\"Error downloading stock data for {ticker}: {e}\")\n","            return pd.DataFrame()\n","\n","        if df.empty:\n","            print(f\"Skipping {ticker}: No historical stock data retrieved.\")\n","            return pd.DataFrame()\n","\n","        # 2. Fetch EPS/PE (Fundamentals)\n","        try:\n","            stock_info = yf.Ticker(ticker).info\n","            stock_eps = stock_info.get('trailingEps', None)\n","\n","            # Use a robust check for EPS\n","            if stock_eps is None or stock_eps == 0:\n","                print(f\"WARNING: EPS not valid for {ticker}. Skipping.\")\n","                return pd.DataFrame()\n","\n","            # 3. Calculate PE and add fundamental features\n","            df['EPS'] = stock_eps\n","            # Calculate PE ratio\n","            df['PE'] = df['Close'] / df['EPS']\n","\n","            # Add other required columns for the rest of the code to work\n","            df['status'] = 'OK'\n","            df['symbol'] = ticker\n","\n","        except Exception as e:\n","            print(f\"Error fetching fundamental data for {ticker}: {e}\")\n","            return pd.DataFrame()\n","\n","        # 4. Merge with bond yield data\n","        df = df.merge(self.closing_yield, how='left', on='from')\n","\n","        # üõ†Ô∏è FIX: Update fillna syntax to suppress FutureWarning\n","        df['5Y_close'] = df['5Y_close'].ffill()\n","        df['10Y_close'] = df['10Y_close'].ffill()\n","\n","        # Rename columns to match the desired format\n","        df.rename(columns={'Open': 'open', 'High': 'high', 'Low': 'low', 'Close': 'close', 'Volume': 'volume'}, inplace=True)\n","\n","        return df\n","\n","# Note: The 'Skipping X due to an unexpected error: name train_test_split is not defined'\n","# will now be resolved by the addition of 'from sklearn.model_selection import train_test_split'\n","# at the top of the combined script."]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","from math import sqrt\n","import warnings\n","\n","warnings.filterwarnings('ignore', category=FutureWarning)\n","\n","# --- Metric Functions ---\n","\n","def calculate_metrics(y_true, y_pred, current_prices):\n","    \"\"\"Calculates MSE, RMSE, R2, and Directional Accuracy.\"\"\"\n","    # 1. MSE and RMSE\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = sqrt(mse)\n","\n","    # 2. R2 Score\n","    r2 = r2_score(y_true, y_pred)\n","\n","    # 3. Directional Accuracy\n","    # Calculate actual price movement direction (1 for up, -1 for down)\n","    # y_true is the 30-day predicted 'open' price. We use the most recent 'close'\n","    # from the original data slice (current_prices) as the comparison point for direction.\n","\n","    # The current price is y_true shifted back 30 days (or the close price at time t)\n","    # Since we dropped the 'close' column in the main loop, we need to ensure 'current_prices'\n","    # holds the correct corresponding price for each day in y_true.\n","\n","    # For the split data (y_train, y_test), we use the 'open' price from 30 days prior (close at time t)\n","    # This requires a corresponding column in the X_train/X_test data.\n","\n","    # Rework: We must align the current price (close) with the predicted price (y).\n","    # The target (y) is df['open'].shift(-30). The price 30 days prior (current price) is df['open'].\n","    # So, we can use the 'open' column in X_train/X_test.\n","\n","    # Get the *actual* stock price (the predictor feature) from the corresponding split data (X_split)\n","    # For training/testing, we use the 'open' column from the corresponding split data as the current price.\n","    # Note: This assumes X_split has an 'open' column, which it does before pd.get_dummies.\n","    # If the X_split dataframe *after* get_dummies is used, the column name will be \"open\".\n","\n","    # Since we are using X_train/X_test (which are one-hot encoded), we must pass the\n","    # *original* open prices from X_train/X_test before one-hot encoding or pass the\n","    # correct 'open' column *before* splitting for this calculation to be accurate.\n","\n","    # To simplify and ensure accuracy: We will use the 'open' column which is\n","    # guaranteed to be a feature in X_train/X_test *before* one-hot encoding.\n","\n","    # The 'current_prices' passed here should be the 'open' price column from X_train/X_test\n","    # that corresponds to the prediction date.\n","\n","    actual_direction = np.sign(y_true - current_prices)\n","    predicted_direction = np.sign(y_pred - current_prices)\n","\n","    # Correct prediction if actual_direction == predicted_direction\n","    directional_accuracy = np.mean(actual_direction == predicted_direction)\n","\n","    return mse, rmse, r2, directional_accuracy\n","\n","# --- Custom Class to Store Results ---\n","\n","class TickerMetrics:\n","    def __init__(self, name, current_close, pred_30d, delta, metrics):\n","        self.name = name\n","        self.current_close = current_close\n","        self.pred_30d = pred_30d\n","        self.delta = delta\n","        self.metrics = metrics # Dictionary to hold all MSE, RMSE, R2, DA\n","\n","# --- Setup and Execution ---\n","\n","stock_output=[]\n","data_raw=StockAPI() # Assuming this is correctly defined and returns a DataFrame\n","\n","stock_basket=['AMZN','AAPL','GOOG','NDAQ','META','TSLA','INTC','AMD']\n","\n","for ticker in stock_basket:\n","    print(f\"\\n--- Processing {ticker} ---\")\n","    try:\n","        # Get historical stock and combined bond data\n","        df = data_raw.update_stock_data(ticker)\n","        print(\"ok\")\n","\n","        # --- Data Validation ---\n","        if df.empty or len(df) < 61: # Need 60+ rows for 30-day prediction + 2 splits\n","            print(f\"Skipping {ticker}: DataFrame is empty or too short.\")\n","            continue\n","\n","        # --- Data Preprocessing ---\n","        print(f\"Data retrieved: {len(df)} rows\")\n","\n","        # Drop columns and create target variable\n","        df = df.drop(columns=['status','EPS','symbol'])\n","\n","        # Create TARGET variable 'pred30d' (Open price 30 days into the future)\n","        df['pred30d'] = df['open'].shift(-30)\n","\n","        # We need the 'open' price at time 't' to calculate directional accuracy later.\n","        # This price is currently in the dataframe and will become a feature in X.\n","\n","        # Create temporal features\n","        df['day_of_week'] = pd.to_datetime(df['from']).dt.dayofweek + 1\n","        df['month'] = pd.to_datetime(df['from']).dt.month\n","\n","        # Store the 'open' price *before* dropping it for the prediction row later\n","        # We will use the last known 'open' price for the prediction delta\n","        current_data_open = df.tail(1)['open'].values[0]\n","\n","        df = df.drop(columns=['from'])\n","\n","        # Reorder columns (pop/insert)\n","        df.insert(loc=0, column=\"day_of_week\", value=df.pop(\"day_of_week\"))\n","        df.insert(loc=0, column=\"month\", value=df.pop(\"month\"))\n","\n","        # Drop NaNs after shift(-30) and bond data joins\n","        df = df.dropna(subset=['pred30d', '5Y_close', '10Y_close'])\n","\n","        # Convert temporal features to categorical\n","        new_format=[\"month\",\"day_of_week\"]\n","        for x in new_format:\n","            df[x] = df[x].astype(\"category\")\n","\n","        # --- Model Setup and Splitting ---\n","        # Feature matrix X (all columns except the target)\n","        X = df.drop(columns=['pred30d'])\n","        # Target vector y\n","        y = df['pred30d']\n","\n","        # We need the 'open' price at time t (the current price feature) to calculate directional accuracy.\n","        # This is the 'open' column in X. Store it before one-hot encoding.\n","        X_current_price = X['open']\n","\n","        # One-hot encode features\n","        X = pd.get_dummies(X)\n","\n","        if X.shape[0] < 3:\n","            print(f\"Skipping {ticker}: Not enough data left for splitting.\")\n","            continue\n","\n","        # 1. TRAIN/TEST split (e.g., 80% Train, 20% Test)\n","        X_train_val, X_test, y_train_val, y_test = train_test_split(\n","            X, y, test_size=0.2, shuffle=False, # Use shuffle=False for time-series\n","            random_state=42\n","        )\n","\n","        # 2. TRAIN/VALIDATION split from X_train_val (e.g., 75% Train, 25% Validation from the 80%)\n","        # This results in a 60/20/20 split of the original data (0.25 * 0.8 = 0.2)\n","        X_train, X_val, y_train, y_val = train_test_split(\n","            X_train_val, y_train_val, test_size=0.25, shuffle=False,\n","            random_state=42\n","        )\n","\n","        # --- Get Current Prices for Directional Accuracy ---\n","        # Get the 'open' price column corresponding to each split\n","        # We must align the split index back to the original X_current_price series\n","        open_train = X_current_price.loc[X_train.index].values\n","        open_val = X_current_price.loc[X_val.index].values\n","        open_test = X_current_price.loc[X_test.index].values\n","\n","        # --- Hyperparameter tuning with GridSearchCV (uses X_train & y_train) ---\n","        parameters = {'n_estimators':[10, 25], 'criterion':['absolute_error', 'squared_error']}\n","        rf_gs = GridSearchCV(RandomForestRegressor(random_state=42), parameters, cv=5, n_jobs=-1, verbose=0)\n","\n","        # Fit on TRAIN set\n","        rf_gs = rf_gs.fit(X_train, y_train)\n","\n","        # Use the best estimator found\n","        best_model = rf_gs.best_estimator_\n","\n","        # --- Predictions for Metrics ---\n","        # Predict on TRAIN set\n","        y_train_pred = best_model.predict(X_train)\n","\n","        # Predict on VALIDATION set\n","        y_val_pred = best_model.predict(X_val)\n","\n","        # Predict on TEST set\n","        y_test_pred = best_model.predict(X_test)\n","\n","        # --- Calculate All Metrics ---\n","\n","        # TRAIN Metrics\n","        train_mse, train_rmse, train_r2, train_da = calculate_metrics(y_train, y_train_pred, open_train)\n","\n","        # VALIDATION Metrics\n","        val_mse, val_rmse, val_r2, val_da = calculate_metrics(y_val, y_val_pred, open_val)\n","\n","        # TEST Metrics\n","        test_mse, test_rmse, test_r2, test_da = calculate_metrics(y_test, y_test_pred, open_test)\n","\n","        # --- Prediction on Current Data (Actual 30d forecast) ---\n","        current_data = df.tail(1).drop(columns=['pred30d']).copy()\n","        current_data_processed = pd.get_dummies(current_data)\n","\n","        # Align columns (crucial for prediction)\n","        current_data_aligned = current_data_processed.reindex(columns=X.columns, fill_value=0)\n","\n","        # Predict 30-day price\n","        stock_30dpred = best_model.predict(current_data_aligned)\n","\n","        # Calculate delta (use the saved 'open' price from the last day as the current price)\n","        current_close = current_data_open # Used 'open' at time t\n","        delta_pred = stock_30dpred[0] / current_close\n","\n","        # --- Store Final Output ---\n","\n","        all_metrics = {\n","            'Train_MSE': train_mse,\n","            'Val_MSE': val_mse,\n","            'Test_MSE': test_mse,\n","            'Train_RMSE': train_rmse,\n","            'Val_RMSE': val_rmse,\n","            'Test_RMSE': test_rmse,\n","            'Train_R2': train_r2,\n","            'Val_R2': val_r2,\n","            'Test_R2': test_r2,\n","            'Train_DA': train_da,\n","            'Test_DA': test_da, # Directional Accuracy is most important on Test\n","            'Val_DA': val_da\n","\n","        }\n","\n","        print(f\"Prediction for {ticker}: Delta={delta_pred:.4f}, Pred={stock_30dpred[0]:.2f}, Close={current_close:.2f}\")\n","        print(f\"Test MSE: {test_mse:.4f}, Test R2: {test_r2:.4f}, Test DA: {test_da:.4f}\")\n","\n","        stock = TickerMetrics(ticker, current_close, stock_30dpred[0], delta_pred, all_metrics)\n","        stock_output.append(stock)\n","\n","    except ValueError as e:\n","        print(f\"Skipping {ticker} due to a processing ValueError: {e}\")\n","    except Exception as e:\n","        print(f\"Skipping {ticker} due to an unexpected error: {e}\")\n","\n","# --- 3. Final Output ---\n","print(\"\\n--- Generating Final Output Table ---\")\n","\n","# Create a DataFrame for output\n","data_list = []\n","for ticker in stock_output:\n","    row = {\n","        \"stock\": ticker.name,\n","        \"current_close\": f\"{ticker.current_close:.2f}\",\n","        \"pred_30d\": f\"{ticker.pred_30d:.2f}\",\n","        \"delta_pred\": f\"{ticker.delta:.4f}\",\n","        \"R2 (Train)\": f\"{ticker.metrics['Train_R2']:.4f}\",\n","        \"R2 (Test)\": f\"{ticker.metrics['Test_R2']:.4f}\",\n","        \"MSE (Train)\": f\"{ticker.metrics['Train_MSE']:.4f}\",\n","        \"MSE (Val)\": f\"{ticker.metrics['Val_MSE']:.4f}\",\n","        \"MSE (Test)\": f\"{ticker.metrics['Test_MSE']:.4f}\",\n","        \"RMSE (Train)\": f\"{ticker.metrics['Train_RMSE']:.4f}\",\n","        \"RMSE (Test)\": f\"{ticker.metrics['Test_RMSE']:.4f}\",\n","        \"DA (Train)\": f\"{ticker.metrics['Train_DA']:.4f}\",\n","        \"DA (Test)\": f\"{ticker.metrics['Test_DA']:.4f}\",\n","        \"DA (Val)\": f\"{ticker.metrics['Val_DA']:.4f}\",\n","    }\n","    data_list.append(row)\n","\n","stock_info_df = pd.DataFrame(data_list)\n","stock_info_df.to_excel(\"/content/drive/MyDrive/Project/output.xlsx\", index=False)\n","\n","print(\"\\n--- Execution Complete ---\")\n","print(f\"Results saved to output.xlsx for {len(stock_output)} tickers.\")"],"metadata":{"id":"7CP_Zj0PGQZy","executionInfo":{"status":"ok","timestamp":1763893136738,"user_tz":-420,"elapsed":40782,"user":{"displayName":"Abhimanyu","userId":"02570476676756296416"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4521d212-4bcd-4108-cda7-87023aa755ab"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Bond Yield data fetched successfully and stored.\n","\n","--- Processing AMZN ---\n","ok\n","Data retrieved: 509 rows\n","Prediction for AMZN: Delta=0.9739, Pred=228.92, Close=235.06\n","Test MSE: 147.3108, Test R2: -0.7561, Test DA: 0.6458\n","\n","--- Processing AAPL ---\n","ok\n","Data retrieved: 509 rows\n","Prediction for AAPL: Delta=0.8667, Pred=234.91, Close=271.05\n","Test MSE: 548.3502, Test R2: -0.1860, Test DA: 0.7188\n","\n","--- Processing GOOG ---\n","ok\n","Data retrieved: 509 rows\n","Prediction for GOOG: Delta=0.6837, Pred=185.91, Close=271.89\n","Test MSE: 4511.4090, Test R2: -2.9357, Test DA: 0.2083\n","\n","--- Processing NDAQ ---\n","ok\n","Data retrieved: 509 rows\n","Prediction for NDAQ: Delta=0.9127, Pred=79.62, Close=87.24\n","Test MSE: 167.0369, Test R2: -12.8617, Test DA: 0.5000\n","\n","--- Processing META ---\n","ok\n","Data retrieved: 509 rows\n","Prediction for META: Delta=0.9975, Pred=600.31, Close=601.79\n","Test MSE: 11328.5530, Test R2: -5.2438, Test DA: 0.5312\n","\n","--- Processing TSLA ---\n","ok\n","Data retrieved: 509 rows\n","Prediction for TSLA: Delta=1.0158, Pred=392.42, Close=386.30\n","Test MSE: 3336.2968, Test R2: -0.0089, Test DA: 0.6458\n","\n","--- Processing INTC ---\n","ok\n","Data retrieved: 509 rows\n","Prediction for INTC: Delta=0.6673, Pred=23.38, Close=35.03\n","Test MSE: 97.6837, Test R2: -0.9215, Test DA: 0.5625\n","\n","--- Processing AMD ---\n","ok\n","Data retrieved: 509 rows\n","Prediction for AMD: Delta=0.5818, Pred=139.70, Close=240.11\n","Test MSE: 3028.8064, Test R2: -1.0489, Test DA: 0.5833\n","\n","--- Generating Final Output Table ---\n","\n","--- Execution Complete ---\n","Results saved to output.xlsx for 8 tickers.\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"18hc85SqX9Mk4Gu5XN_blgLg7xl3zJgvt","timestamp":1763793716908},{"file_id":"1Rn6rODeGJ0ND88QHnfZXeKZ4w-oe6e5X","timestamp":1763616111684},{"file_id":"15m1lylzlGt_DQfYXhT-rI_8uxqxkgaFm","timestamp":1697958652518}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}