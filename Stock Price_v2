{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"5UTMFBeOWNKp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from getpass import getpass\n","\n","# ğŸ”¹ Your ML project folder (EXACT PATH)\n","project_path = \"/content/drive/MyDrive/Project\" # your path\n","os.chdir(project_path)\n","\n","print(\"Working directory:\", os.getcwd())\n","!ls\n","\n","# # ğŸ”¹ Initialize Git (safe to run even if repo already exists)\n","# !git init\n","\n","# ğŸ”¹ Git user identity\n","!git config --global user.name \"manyu-88\"\n","!git config --global user.email \"abhimanyu_shirwalkar2015@pgp.isb.edu\"\n","\n","# ğŸ”¹ Ensure main branch\n","!git branch -M main\n","\n","# ğŸ”¹ GitHub repo config (EXACT FOR YOU)\n","username = \"manyu-88\"\n","repo_name = \"stock-price-model\" # your repo\n","\n","# # ğŸ”¹ Ask for GitHub Personal Access Token secretly\n","token = getpass(\"Enter your GitHub Personal Access Token: \")\n","\n","# ğŸ”¹ Set remote origin (replace if exists)\n","remote_url = f\"https://{token}@github.com/{username}/{repo_name}.git\"\n","!git remote remove origin 2>/dev/null || true\n","!git remote add origin $remote_url\n","\n","\n"],"metadata":{"id":"rnU3-1j9TNG_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ğŸ”¹ Add and commit everything\n","!git add .\n","!git commit -m \"Second Run for Stock Price Prediction ML project w Basic RF\"\n","\n","# ğŸ”¹ Push to GitHub\n","!git push -u origin main\n","!git push -u origin main --force"],"metadata":{"id":"oCK9IyovXyGw"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jOKOBZlwN1a5"},"outputs":[],"source":["!pip install schedule\n","!pip install requests"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EIKTsRpDOIVB"},"outputs":[],"source":["import time\n","import requests\n","import pandas as pd\n","from datetime import datetime,timedelta\n","import schedule\n","import pytz\n","import csv\n","import yfinance as yf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ex1Vd4LPOQU2"},"outputs":[],"source":["import time\n","import requests\n","import pandas as pd\n","from datetime import datetime, timedelta\n","import schedule\n","import pytz\n","import csv\n","import yfinance as yf\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import RandomForestRegressor\n","\n","# ğŸ› ï¸ FIX: Import for the downstream error 'train_test_split is not defined'\n","from sklearn.model_selection import train_test_split\n","\n","class TickerInfo:\n","    \"\"\"Class to hold the prediction results for each stock.\"\"\"\n","    def __init__(self, name, score, delta):\n","        self.name = name\n","        self.score = score\n","        self.delta = delta\n","\n","class StockAPI():\n","    \"\"\"Handles data retrieval from yfinance.\"\"\"\n","\n","    def __init__(self):\n","        # Set a realistic historical date range (e.g., 2 years ending in mid-2025)\n","        self.date_end = datetime(2025, 11, 15)\n","        # Calculate start date ~2 years back, adjusting for trading days\n","        self.date_start = self.date_end - timedelta(days=5 * 365 + 10)\n","\n","        # Fetch bond data once upon initialization\n","        self.closing_yield = self._fetch_yield_data()\n","        print(\"Bond Yield data fetched successfully and stored.\")\n","\n","    def _fetch_yield_data(self):\n","        \"\"\"\n","        Fetches 5Y and 10Y T-Bond yield data once using yfinance.\n","        Guarantees return of an indexed DataFrame (or an empty one).\n","        \"\"\"\n","        end_date_str = self.date_end.strftime(\"%Y-%m-%d\")\n","        start_date_str = self.date_start.strftime(\"%Y-%m-%d\")\n","\n","        # Default empty DataFrame to return on failure\n","        empty_df = pd.DataFrame({'from': pd.Series([], dtype='datetime64[ns]'),\n","                                 '5Y_close': [],\n","                                 '10Y_close': []})\n","        try:\n","            # Setting progress=False to suppress output during download\n","            # Added auto_adjust=False to suppress FutureWarning\n","            tbond_5y = yf.download(tickers=\"^FVX\", start=start_date_str, end=end_date_str, progress=False, auto_adjust=False)\n","            tbond_10y = yf.download(tickers=\"^TNX\", start=start_date_str, end=end_date_str, progress=False, auto_adjust=False)\n","\n","            # Robustly handle potential MultiIndex in bond data (Fix 2)\n","            if isinstance(tbond_5y.columns, pd.MultiIndex):\n","                tbond_5y.columns = tbond_5y.columns.get_level_values(0)\n","            if isinstance(tbond_10y.columns, pd.MultiIndex):\n","                tbond_10y.columns = tbond_10y.columns.get_level_values(0)\n","\n","            # Reset index to move 'Date' from index to a column for merging\n","            tbond_5y = tbond_5y.reset_index()\n","            tbond_10y = tbond_10y.reset_index()\n","\n","        except Exception as e:\n","            print(f\"Error during yfinance download for bonds: {e}\")\n","            return empty_df\n","\n","        # Robust check for valid time-series data\n","        has_5y_data = 'Close' in tbond_5y.columns and len(tbond_5y) > 1\n","        has_10y_data = 'Close' in tbond_10y.columns and len(tbond_10y) > 1\n","\n","        if not has_5y_data or not has_10y_data:\n","            print(\"WARNING: Bond data is incomplete or empty. Returning empty DataFrame.\")\n","            return empty_df\n","\n","        try:\n","            # Select the Date and Close columns and rename the Close columns\n","            df_5y = tbond_5y[['Date', 'Close']].rename(columns={'Close': '5Y_close'})\n","            df_10y = tbond_10y[['Date', 'Close']].rename(columns={'Close': '10Y_close'})\n","\n","            # Use pd.merge to combine the two dataframes on the common 'Date' column\n","            closing_yield = pd.merge(df_5y, df_10y, on='Date', how='inner')\n","\n","            # Rename the 'Date' column to 'from' to match the stock data format\n","            closing_yield = closing_yield.rename(columns={'Date': 'from'})\n","\n","            # ğŸ› ï¸ FIX: Update fillna syntax to suppress FutureWarning\n","            closing_yield['5Y_close'] = closing_yield['5Y_close'].ffill()\n","            closing_yield['10Y_close'] = closing_yield['10Y_close'].ffill()\n","\n","            return closing_yield\n","\n","        except Exception as e:\n","            # Catch errors during processing\n","            print(f\"Error processing bond data after download: {e}\")\n","            return empty_df\n","\n","    def update_stock_data(self, ticker):\n","\n","        start_date_str = self.date_start.strftime(\"%Y-%m-%d\")\n","        end_date_str = self.date_end.strftime(\"%Y-%m-%d\")\n","\n","        # 1. Fetch historical OHLCV data for the entire range using yfinance\n","        try:\n","            df = yf.download(ticker, start=start_date_str, end=end_date_str, progress=False, auto_adjust=False)\n","\n","            if isinstance(df.columns, pd.MultiIndex):\n","                # Dropping the second level (the ticker symbol) from the MultiIndex\n","                df.columns = df.columns.droplevel(1)\n","\n","            # Move Date index to 'from' column\n","            df = df.reset_index().rename(columns={'Date': 'from'})\n","\n","        except Exception as e:\n","            print(f\"Error downloading stock data for {ticker}: {e}\")\n","            return pd.DataFrame()\n","\n","        if df.empty:\n","            print(f\"Skipping {ticker}: No historical stock data retrieved.\")\n","            return pd.DataFrame()\n","\n","        # 2. Fetch EPS/PE (Fundamentals)\n","        try:\n","            stock_info = yf.Ticker(ticker).info\n","            stock_eps = stock_info.get('trailingEps', None)\n","\n","            # Use a robust check for EPS\n","            if stock_eps is None or stock_eps == 0:\n","                print(f\"WARNING: EPS not valid for {ticker}. Skipping.\")\n","                return pd.DataFrame()\n","\n","            # 3. Calculate PE and add fundamental features\n","            df['EPS'] = stock_eps\n","            # Calculate PE ratio\n","            df['PE'] = df['Close'] / df['EPS']\n","\n","            # Add other required columns for the rest of the code to work\n","            df['status'] = 'OK'\n","            df['symbol'] = ticker\n","\n","        except Exception as e:\n","            print(f\"Error fetching fundamental data for {ticker}: {e}\")\n","            return pd.DataFrame()\n","\n","        # 4. Merge with bond yield data\n","        df = df.merge(self.closing_yield, how='left', on='from')\n","\n","        # ğŸ› ï¸ FIX: Update fillna syntax to suppress FutureWarning\n","        df['5Y_close'] = df['5Y_close'].ffill()\n","        df['10Y_close'] = df['10Y_close'].ffill()\n","\n","        # Rename columns to match the desired format\n","        df.rename(columns={'Open': 'open', 'High': 'high', 'Low': 'low', 'Close': 'close', 'Volume': 'volume'}, inplace=True)\n","\n","        return df\n","\n","# Note: The 'Skipping X due to an unexpected error: name train_test_split is not defined'\n","# will now be resolved by the addition of 'from sklearn.model_selection import train_test_split'\n","# at the top of the combined script."]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","from math import sqrt\n","import warnings\n","\n","warnings.filterwarnings('ignore', category=FutureWarning)\n","\n","# --- CONFIGURATION ---\n","PREDICTION_HORIZON = 5 # Days into the future to predict\n","# ---------------------\n","\n","# --- Metric Functions ---\n","\n","def calculate_metrics(y_true, y_pred, current_prices):\n","Â  Â  \"\"\"Calculates MSE, RMSE, R2, and Directional Accuracy.\"\"\"\n","Â  Â  # 1. MSE and RMSE\n","Â  Â  mse = mean_squared_error(y_true, y_pred)\n","Â  Â  rmse = sqrt(mse)\n","\n","Â  Â  # 2. R2 Score\n","Â  Â  r2 = r2_score(y_true, y_pred)\n","\n","Â  Â  # 3. Directional Accuracy\n","Â  Â  # The 'current_prices' is the 'open' price at time t (5 days prior to y_true)\n","Â  Â  actual_direction = np.sign(y_true - current_prices)\n","Â  Â  predicted_direction = np.sign(y_pred - current_prices)\n","\n","Â  Â  # Correct prediction if actual_direction == predicted_direction\n","Â  Â  directional_accuracy = np.mean(actual_direction == predicted_direction)\n","\n","Â  Â  return mse, rmse, r2, directional_accuracy\n","\n","# --- Custom Class to Store Results ---\n","\n","class TickerMetrics:\n","Â  Â  # Renamed pred_30d to pred_5d\n","Â  Â  def __init__(self, name, current_close, pred_5d, delta, metrics):\n","Â  Â  Â  Â  self.name = name\n","Â  Â  Â  Â  self.current_close = current_close\n","Â  Â  Â  Â  self.pred_5d = pred_5d\n","Â  Â  Â  Â  self.delta = delta\n","Â  Â  Â  Â  self.metrics = metrics # Dictionary to hold all MSE, RMSE, R2, DA\n","\n","# --- Setup and Execution ---\n","\n","stock_output=[]\n","data_raw=StockAPI() # Assuming this is correctly defined and returns a DataFrame\n","\n","stock_basket=['AMZN','AAPL','GOOG','NDAQ','META','TSLA','INTC','AMD']\n","\n","for ticker in stock_basket:\n","Â  Â  print(f\"\\n--- Processing {ticker} ---\")\n","Â  Â  try:\n","Â  Â  Â  Â  # Get historical stock and combined bond data\n","Â  Â  Â  Â  df = data_raw.update_stock_data(ticker)\n","Â  Â  Â  Â  print(\"ok\")\n","\n","Â  Â  Â  Â  # --- Data Validation ---\n","Â  Â  Â  Â  # Updated check to PREDICTION_HORIZON + splits (e.g., 5 + ~2 splits)\n","Â  Â  Â  Â  if df.empty or len(df) < (PREDICTION_HORIZON + 2):\n","Â  Â  Â  Â  Â  Â  print(f\"Skipping {ticker}: DataFrame is empty or too short.\")\n","Â  Â  Â  Â  Â  Â  continue\n","\n","Â  Â  Â  Â  # --- Data Preprocessing ---\n","Â  Â  Â  Â  print(f\"Data retrieved: {len(df)} rows\")\n","\n","Â  Â  Â  Â  # Drop columns and create target variable\n","Â  Â  Â  Â  df = df.drop(columns=['status','EPS','symbol'])\n","\n","Â  Â  Â  Â  # Create TARGET variable 'pred5d' (Open price 5 days into the future)\n","Â  Â  Â  Â  # KEY CHANGE: shift(-5) instead of shift(-30)\n","Â  Â  Â  Â  df['pred5d'] = df['open'].shift(-PREDICTION_HORIZON)\n","\n","Â  Â  Â  Â  # We need the 'open' price at time 't' to calculate directional accuracy later.\n","Â  Â  Â  Â  # This price is currently in the dataframe and will become a feature in X.\n","\n","Â  Â  Â  Â  # Create temporal features\n","Â  Â  Â  Â  df['day_of_week'] = pd.to_datetime(df['from']).dt.dayofweek + 1\n","Â  Â  Â  Â  df['month'] = pd.to_datetime(df['from']).dt.month\n","\n","Â  Â  Â  Â  # Store the 'open' price *before* dropping it for the prediction row later\n","Â  Â  Â  Â  # We will use the last known 'open' price for the prediction delta\n","Â  Â  Â  Â  current_data_open = df.tail(1)['open'].values[0]\n","\n","Â  Â  Â  Â  df = df.drop(columns=['from'])\n","\n","Â  Â  Â  Â  # Reorder columns (pop/insert)\n","Â  Â  Â  Â  df.insert(loc=0, column=\"day_of_week\", value=df.pop(\"day_of_week\"))\n","Â  Â  Â  Â  df.insert(loc=0, column=\"month\", value=df.pop(\"month\"))\n","\n","Â  Â  Â  Â  # Drop NaNs after shift(-5) and bond data joins\n","Â  Â  Â  Â  # KEY CHANGE: Changed 'pred30d' to 'pred5d' in dropna\n","Â  Â  Â  Â  df = df.dropna(subset=['pred5d', '5Y_close', '10Y_close'])\n","\n","Â  Â  Â  Â  # Convert temporal features to categorical\n","Â  Â  Â  Â  new_format=[\"month\",\"day_of_week\"]\n","Â  Â  Â  Â  for x in new_format:\n","Â  Â  Â  Â  Â  Â  df[x] = df[x].astype(\"category\")\n","\n","Â  Â  Â  Â  # --- Model Setup and Splitting ---\n","Â  Â  Â  Â  # Feature matrix X (all columns except the target)\n","Â  Â  Â  Â  # KEY CHANGE: Changed 'pred30d' to 'pred5d' for drop\n","Â  Â  Â  Â  X = df.drop(columns=['pred5d'])\n","Â  Â  Â  Â  # Target vector y\n","Â  Â  Â  Â  # KEY CHANGE: Changed 'pred30d' to 'pred5d' for target\n","Â  Â  Â  Â  y = df['pred5d']\n","\n","Â  Â  Â  Â  # We need the 'open' price at time t (the current price feature) to calculate directional accuracy.\n","Â  Â  Â  Â  # This is the 'open' column in X. Store it before one-hot encoding.\n","Â  Â  Â  Â  X_current_price = X['open']\n","\n","Â  Â  Â  Â  # One-hot encode features\n","Â  Â  Â  Â  X = pd.get_dummies(X)\n","\n","Â  Â  Â  Â  if X.shape[0] < 3:\n","Â  Â  Â  Â  Â  Â  print(f\"Skipping {ticker}: Not enough data left for splitting.\")\n","Â  Â  Â  Â  Â  Â  continue\n","\n","Â  Â  Â  Â  # 1. TRAIN/TEST split (e.g., 70% Train, 30% Test)\n","Â  Â  Â  Â  X_train_val, X_test, y_train_val, y_test = train_test_split(\n","Â  Â  Â  Â  Â  Â  X, y, test_size=0.3, shuffle=False, # Use shuffle=False for time-series\n","Â  Â  Â  Â  Â  Â  random_state=42\n","Â  Â  Â  Â  )\n","\n","Â  Â  Â  Â  # 2. TRAIN/VALIDATION split from X_train_val (e.g., 75% Train, 25% Validation from the 80%)\n","Â  Â  Â  Â  # This results in a 60/20/20 split of the original data (0.25 * 0.8 = 0.2)\n","Â  Â  Â  Â  X_train, X_val, y_train, y_val = train_test_split(\n","Â  Â  Â  Â  Â  Â  X_train_val, y_train_val, test_size=0.50, shuffle=False,\n","Â  Â  Â  Â  Â  Â  random_state=42\n","Â  Â  Â  Â  )\n","\n","Â  Â  Â  Â  # --- Get Current Prices for Directional Accuracy ---\n","Â  Â  Â  Â  # Get the 'open' price column corresponding to each split\n","Â  Â  Â  Â  # We must align the split index back to the original X_current_price series\n","Â  Â  Â  Â  open_train = X_current_price.loc[X_train.index].values\n","Â  Â  Â  Â  open_val = X_current_price.loc[X_val.index].values\n","Â  Â  Â  Â  open_test = X_current_price.loc[X_test.index].values\n","\n","Â  Â  Â  Â  # --- Hyperparameter tuning with GridSearchCV (uses X_train & y_train) ---\n","Â  Â  Â  Â  parameters = {'n_estimators':[10, 25], 'criterion':['absolute_error', 'squared_error']}\n","Â  Â  Â  Â  rf_gs = GridSearchCV(RandomForestRegressor(random_state=42), parameters, cv=5, n_jobs=-1, verbose=0)\n","\n","Â  Â  Â  Â  # Fit on TRAIN set\n","Â  Â  Â  Â  rf_gs = rf_gs.fit(X_train, y_train)\n","\n","Â  Â  Â  Â  # Use the best estimator found\n","Â  Â  Â  Â  best_model = rf_gs.best_estimator_\n","\n","Â  Â  Â  Â  # --- Predictions for Metrics ---\n","Â  Â  Â  Â  # Predict on TRAIN set\n","Â  Â  Â  Â  y_train_pred = best_model.predict(X_train)\n","\n","Â  Â  Â  Â  # Predict on VALIDATION set\n","Â  Â  Â  Â  y_val_pred = best_model.predict(X_val)\n","\n","Â  Â  Â  Â  # Predict on TEST set\n","Â  Â  Â  Â  y_test_pred = best_model.predict(X_test)\n","\n","Â  Â  Â  Â  # --- Calculate All Metrics ---\n","\n","Â  Â  Â  Â  # TRAIN Metrics\n","Â  Â  Â  Â  train_mse, train_rmse, train_r2, train_da = calculate_metrics(y_train, y_train_pred, open_train)\n","\n","Â  Â  Â  Â  # VALIDATION Metrics\n","Â  Â  Â  Â  val_mse, val_rmse, val_r2, val_da = calculate_metrics(y_val, y_val_pred, open_val)\n","\n","Â  Â  Â  Â  # TEST Metrics\n","Â  Â  Â  Â  test_mse, test_rmse, test_r2, test_da = calculate_metrics(y_test, y_test_pred, open_test)\n","\n","Â  Â  Â  Â  # --- Prediction on Current Data (Actual 5d forecast) ---\n","Â  Â  Â  Â  # KEY CHANGE: Changed 'pred30d' to 'pred5d' for drop\n","Â  Â  Â  Â  current_data = df.tail(1).drop(columns=['pred5d']).copy()\n","Â  Â  Â  Â  current_data_processed = pd.get_dummies(current_data)\n","\n","Â  Â  Â  Â  # Align columns (crucial for prediction)\n","Â  Â  Â  Â  current_data_aligned = current_data_processed.reindex(columns=X.columns, fill_value=0)\n","\n","Â  Â  Â  Â  # Predict 5-day price\n","Â  Â  Â  Â  # KEY CHANGE: Renamed variable to stock_5dpred\n","Â  Â  Â  Â  stock_5dpred = best_model.predict(current_data_aligned)\n","\n","Â  Â  Â  Â  # Calculate delta (use the saved 'open' price from the last day as the current price)\n","Â  Â  Â  Â  current_close = current_data_open # Used 'open' at time t\n","Â  Â  Â  Â  delta_pred = stock_5dpred[0] / current_close\n","\n","Â  Â  Â  Â  # --- Store Final Output ---\n","\n","Â  Â  Â  Â  all_metrics = {\n","Â  Â  Â  Â  Â  Â  # 'Train_MSE': train_mse,\n","Â  Â  Â  Â  Â  Â  'Val_MSE': val_mse,\n","Â  Â  Â  Â  Â  Â  'Test_MSE': test_mse,\n","Â  Â  Â  Â  Â  Â  # 'Train_RMSE': train_rmse,\n","Â  Â  Â  Â  Â  Â  'Val_RMSE': val_rmse,\n","Â  Â  Â  Â  Â  Â  'Test_RMSE': test_rmse,\n","Â  Â  Â  Â  Â  Â  # 'Train_R2': train_r2,\n","Â  Â  Â  Â  Â  Â  'Val_R2': val_r2,\n","Â  Â  Â  Â  Â  Â  'Test_R2': test_r2,\n","Â  Â  Â  Â  Â  Â  # 'Train_DA': train_da,\n","Â  Â  Â  Â  Â  Â  'Test_DA': test_da, # Directional Accuracy is most important on Test\n","Â  Â  Â  Â  Â  Â  'Val_DA': val_da\n","\n","Â  Â  Â  Â  }\n","\n","Â  Â  Â  Â  # KEY CHANGE: Updated print statement for 5-day prediction\n","Â  Â  Â  Â  print(f\"Prediction for {ticker}: Delta={delta_pred:.4f}, Pred={stock_5dpred[0]:.2f}, Close={current_close:.2f}\")\n","Â  Â  Â  Â  print(f\"Test MSE: {test_mse:.4f}, Test R2: {test_r2:.4f}, Test DA: {test_da:.4f}\")\n","\n","Â  Â  Â  Â  # KEY CHANGE: Passed stock_5dpred to TickerMetrics\n","Â  Â  Â  Â  stock = TickerMetrics(ticker, current_close, stock_5dpred[0], delta_pred, all_metrics)\n","Â  Â  Â  Â  stock_output.append(stock)\n","\n","Â  Â  except ValueError as e:\n","Â  Â  Â  Â  print(f\"Skipping {ticker} due to a processing ValueError: {e}\")\n","Â  Â  except Exception as e:\n","Â  Â  Â  Â  print(f\"Skipping {ticker} due to an unexpected error: {e}\")\n","\n","# --- 3. Final Output ---\n","print(\"\\n--- Generating Final Output Table ---\")\n","\n","# Create a DataFrame for output\n","data_list = []\n","for ticker in stock_output:\n","Â  Â  row = {\n","Â  Â  Â  Â  \"stock\": ticker.name,\n","Â  Â  Â  Â  # \"current_close\": f\"{ticker.current_close:.2f}\",\n","Â  Â  Â  Â  # KEY CHANGE: Updated column tag for 5-day prediction\n","Â  Â  Â  Â  \"pred_5d\": f\"{ticker.pred_5d:.2f}\",\n","Â  Â  Â  Â  # \"delta_pred\": f\"{ticker.delta:.4f}\",\n","Â  Â  Â  Â  # \"R2 (Train)\": f\"{ticker.metrics['Train_R2']:.4f}\",\n","Â  Â  Â  Â  \"R2 (Test)\": f\"{ticker.metrics['Test_R2']:.4f}\",\n","Â  Â  Â  Â  \"R2 (Val)\": f\"{ticker.metrics['Val_R2']:.4f}\",\n","Â  Â  Â  Â  # \"MSE (Train)\": f\"{ticker.metrics['Train_MSE']:.4f}\",\n","Â  Â  Â  Â  \"MSE (Test)\": f\"{ticker.metrics['Test_MSE']:.4f}\",\n","Â  Â  Â  Â  \"MSE (Val)\": f\"{ticker.metrics['Val_MSE']:.4f}\",\n","Â  Â  Â  Â  # \"RMSE (Train)\": f\"{ticker.metrics['Train_RMSE']:.4f}\",\n","Â  Â  Â  Â  \"RMSE (Test)\": f\"{ticker.metrics['Test_RMSE']:.4f}\",\n","Â  Â  Â  Â  \"RMSE (Val)\": f\"{ticker.metrics['Val_RMSE']:.4f}\",\n","Â  Â  Â  Â  # \"DA (Train)\": f\"{ticker.metrics['Train_DA']:.4f}\",\n","Â  Â  Â  Â  \"DA (Test)\": f\"{ticker.metrics['Test_DA']:.4f}\",\n","Â  Â  Â  Â  \"DA (Val)\": f\"{ticker.metrics['Val_DA']:.4f}\",\n","Â  Â  }\n","Â  Â  data_list.append(row)\n","\n","stock_info_df = pd.DataFrame(data_list)\n","stock_info_df.to_excel(\"/content/drive/MyDrive/Project/output.xlsx\", index=False)\n","\n","print(\"\\n--- Execution Complete ---\")\n","print(f\"Results saved to output.xlsx for {len(stock_output)} tickers.\")"],"metadata":{"id":"7CP_Zj0PGQZy"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"18hc85SqX9Mk4Gu5XN_blgLg7xl3zJgvt","timestamp":1763793716908},{"file_id":"1Rn6rODeGJ0ND88QHnfZXeKZ4w-oe6e5X","timestamp":1763616111684},{"file_id":"15m1lylzlGt_DQfYXhT-rI_8uxqxkgaFm","timestamp":1697958652518}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}